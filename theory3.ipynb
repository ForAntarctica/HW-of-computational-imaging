{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业一\n",
    "VAE是一种神经网络，以无监督学习的方式压缩数据，并且可以将它通过解码器恢复出来。它的训练依赖于变分贝叶斯和概率建模。\n",
    "其中，Evidence Lower Bound (ELBO) 为：\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p_{\\theta}(z)) - E_{q_{\\phi}(z|x)} \\log p_{\\theta}(x|z)\n",
    "$$\n",
    "目标函数为\n",
    "$$\n",
    "\\hat{\\theta} = \\arg \\max \\limits_{\\theta} \\sum \\limits_{i = 1}^{n} \\log p_{\\theta}(x^{(i)})\n",
    "$$\n",
    "但是在实际过程中，该公式无法计算，实际按照ELBO作为目标函数：\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\phi; \\mathbf{x}) = \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} \\left[ \\log p_\\theta(\\mathbf{x}|\\mathbf{z}) \\right] - \\text{D}_{KL}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_{\\theta}(\\mathbf{z})\\right)\n",
    "$$\n",
    "\n",
    "# 作业二\n",
    "DDPM中存在两个过程，一个前向过程，一个反向过程，一个这两种过程被视为参数化的随机马尔可夫链。在前向过程中，向图像中添加高斯噪声，最后达到均值和方差为0的高斯分布，在反向过程中，算法尝试从高斯噪声分布中重建无噪声图像。在DDPM中目标函数是使得数据的边缘似然函数最大化，但实际操作中，选择最大化ELBO函数。其中他的变分下界为：\n",
    "$$\\mathbb{E}_{q(\\mathbf{x}_{1:T} \\mid \\mathbf{x}_0)} \\left[ \\log p_\\theta(\\mathbf{x}_0 \\mid \\mathbf{x}_1) \\right] - \\sum_{t=2}^{T} \\text{KL}\\left(q(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t) \\right) - \\text{KL}\\left(q(\\mathbf{x}_T \\mid \\mathbf{x}_0) \\| p(\\mathbf{x}_T) \\right)\n",
    "$$\n",
    "它的目标函数为：\n",
    "$$\n",
    "-\\mathcal{L}(\\theta; \\mathbf{x}_0) = \\mathbb{E}_{q(\\mathbf{x}_{1:T} \\mid \\mathbf{x}_0)} \\left[ \\log p_\\theta(\\mathbf{x}_0 \\mid \\mathbf{x}_1) \\right] - \\sum_{t=2}^{T} \\text{KL}\\left(q(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t) \\right) - \\text{KL}\\left(q(\\mathbf{x}_T \\mid \\mathbf{x}_0) \\| p(\\mathbf{x}_T) \\right)\n",
    "$$\n",
    "# 作业三\n",
    "VAE通过潜在变量的采样和解码器生成样本，依赖于潜在空间的概率分布。DDPM通过逐步去除噪声，从纯噪声逐步生成样本，依赖于扩散和逆扩散过程。在生成速度方面，由于VAE只需要传播一次，因此生成速度较快，DDPM生成速度较慢，但从生成样本质量看，DDPM生成的样本质量更高，更接近于真实样本。而且VAE模型的架构一般为编码器-解码器架构，DDPM为U-net。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
